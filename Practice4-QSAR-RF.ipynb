{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e27d554",
   "metadata": {},
   "source": [
    "# Predictive Toxicology using QSAR Analysis with RDKit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e9055",
   "metadata": {},
   "source": [
    "This Jupyter Notebook aims to explore Quantitative Structure-Activity Relationship (QSAR) analysis with a focus on predicting toxicity.\n",
    "\n",
    "QSAR workflow involves two main steps:\n",
    "\n",
    "**Step 1: Creating the Mathematical Model for Toxicity**\n",
    "\n",
    "    In the first step, we create a mathematical model for toxicity using the available dataset. This model is based on the quantitative relationship between the chemical properties of compounds (molecular fingerprints)  and their toxicity. \n",
    "\n",
    "**Step 2: Using the Toxicity Model for Filtering Ligand-Based Virtual Screening**\n",
    "\n",
    "    Once the QSAR model is created and validated, you can utilize it for filtering compounds in ligand-based virtual screening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b02fd",
   "metadata": {},
   "source": [
    "### Step 1: Creating the Mathematical Model for Toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf0737",
   "metadata": {},
   "source": [
    "***Dataset Preparation***: Load the toxicity dataset. This data set includes information on the toxicity of several chemical compounds related with liver toxicity. Cleans the database: removes compounds with salts, removes charges, removes Nan elements. \n",
    "\n",
    "***Descriptor Calculation***: Calculate molecular descriptors for each compound in the dataset using RDKit. \n",
    "\n",
    "***Model Building***: Select a suitable machine learning or statistical model. Train the model using the computed molecular descriptors as features and the toxicity data as the target variable.\n",
    "\n",
    "    Model Validation: Evaluate the performance of the model using validation techniques like cross-validation, RMSE, R2score...\n",
    "\n",
    "    Model Optimization: Fine-tune the model parameters to improve its predictive performance, if needed.\n",
    "\n",
    "    Model Interpretation: Analyze the model to understand which molecular features contribute to toxicity predictions. This insight can be valuable for designing safer compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a90fe4",
   "metadata": {},
   "source": [
    "**Machine Learning in Python: Scikit-learn**\n",
    "\n",
    "[Scikit-learn webpage](https://scikit-learn.org/stable/index.html)\n",
    "\n",
    "[Scikit-learn GitHub](https://github.com/scikit-learn/scikit-learn)\n",
    "\n",
    "[Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264395c",
   "metadata": {},
   "source": [
    "***Dataset Preparation***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787dcb6",
   "metadata": {},
   "source": [
    "Initial Dataset related with liver toxicity obtained from: https://www.fda.gov/science-research/liver-toxicity-knowledge-base-ltkb/drug-induced-liver-injury-rank-dilirank-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c23a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'LiverToxdf.xlsx'\n",
    "# Load the Excel file into a DataFrame\n",
    "df_tox = pd.read_excel(excel_file)\n",
    "df_tox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a710cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NaN \n",
    "df_tox_cleaned = df_tox.dropna().reset_index(drop=True)\n",
    "len(df_tox_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cae777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with compounds containing charges\n",
    "df_tox_cleaned = df_tox_cleaned[df_tox_cleaned['SMILES'].apply(lambda x: all(atom.GetFormalCharge() == 0 for atom in Chem.MolFromSmiles(x).GetAtoms()))].reset_index(drop=True)\n",
    "len(df_tox_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0add29e",
   "metadata": {},
   "source": [
    "    df_tox_cleaned['SMILES'].apply(lambda x: all(atom.GetFormalCharge() == 0 for atom in Chem.MolFromSmiles(x).GetAtoms())): This part of the code applies a lambda function to each value in the 'SMILES' column of the DataFrame. The lambda function converts the SMILES string into a chemical molecule using the RDKit library (Chem.MolFromSmiles(x)), and then checks that all formal charges of atoms in that molecule are equal to zero (atom.GetFormalCharge() == 0).\n",
    "\n",
    "    df_tox_cleaned[...]: It filters the original DataFrame (df_tox_cleaned) by keeping only the rows where the above condition is true. In other words, rows containing molecules with atoms having formal charges different from zero are removed.\n",
    "\n",
    "    .reset_index(drop=True): After filtering the DataFrame, the index is reset to reflect the new dataset without the removed rows. The argument drop=True prevents the addition of an additional column to store the old indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc7d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of compounds in each severity class category\n",
    "severity_counts = df_tox_cleaned['Severity Class'].value_counts().sort_index()\n",
    "severity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b351303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart with matplotlib\n",
    "plt.bar(severity_counts.index, severity_counts, edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Severity Class')\n",
    "plt.ylabel('Number of Compounds')\n",
    "plt.title('Count of Compounds by Severity Category')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6528a",
   "metadata": {},
   "source": [
    "When dealing with imbalanced datasets, where certain classes are underrepresented, undersampling is a technique that involves reducing the number of instances in the majority class to balance the distribution. Remember that undersampling can lead to a loss of information, and its success depends on the specific characteristics of your dataset and the problem you are addressing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe042a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most populated class\n",
    "most_populated_class = severity_counts.idxmax()\n",
    "\n",
    "# Set the desired number of instances for all classes (you can adjust it according to your needs)\n",
    "desired_size = 40\n",
    "\n",
    "# Create an empty DataFrame to store the balanced dataset\n",
    "balanced_df = pd.DataFrame()\n",
    "\n",
    "# Apply undersampling only to the most populated class\n",
    "for severity_class, count in severity_counts.items():\n",
    "    if severity_class == most_populated_class:\n",
    "        # If it's the most populated class, reduce the number of instances to desired_size\n",
    "        undersampled_indices = df_tox_cleaned[df_tox_cleaned['Severity Class'] == severity_class].sample(n=desired_size, random_state=42).index\n",
    "    else:\n",
    "        # If it's not the most populated class, include all instances\n",
    "        undersampled_indices = df_tox_cleaned[df_tox_cleaned['Severity Class'] == severity_class].index\n",
    "\n",
    "    # Concatenate the undersampled indices to the balanced DataFrame\n",
    "    balanced_df = pd.concat([balanced_df, df_tox_cleaned.loc[undersampled_indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adeaf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of compounds in each severity class category\n",
    "severity_counts2 = balanced_df['Severity Class'].value_counts().sort_index()\n",
    "severity_counts2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e627e",
   "metadata": {},
   "source": [
    "**Descriptors Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f04568",
   "metadata": {},
   "outputs": [],
   "source": [
    "maccs_fingerprints_list = []\n",
    "\n",
    "# Step 3: Iterate through the SMILES column and calculate descriptors\n",
    "for k, row in df_tox_cleaned.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row.SMILES)\n",
    "    \n",
    "        # Calculate MACCS fingerprints\n",
    "    maccs_fingerprints = AllChem.GetMACCSKeysFingerprint(mol)\n",
    "    maccs_fingerprints_list.append(\n",
    "        {\"Compound Name\": row[\"Compound Name\"], \"smiles\": row[\"SMILES\"], \"fingerprint\": maccs_fingerprints}\n",
    "    )\n",
    "\n",
    "# Crear un DataFrame a partir de la lista de huellas peptídicas MACCS\n",
    "df_maccs = pd.DataFrame(maccs_fingerprints_list)\n",
    "df_maccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eb0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tox_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87a8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tox_cleaned = pd.merge(df_tox_cleaned, df_maccs, on='Compound Name')\n",
    "df_tox_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e259273",
   "metadata": {},
   "source": [
    "Data Splitting\n",
    "Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08148595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variables\n",
    "X = np.array(df_tox_cleaned['fingerprint'].to_list())\n",
    "Y = df_tox_cleaned['Severity Class']  # The target variable\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f84f0b",
   "metadata": {},
   "source": [
    "***Model Building:Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Random Forest regression model\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(Y_test, Y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(Y_test, Y_pred_rf)\n",
    "pearson_corr_rf = np.corrcoef(Y_test, Y_pred_rf)[0, 1]\n",
    "mae_rf = mean_absolute_error(Y_test, Y_pred_rf)\n",
    "\n",
    "# Print the calculated metrics for Random Forest\n",
    "print(f'Random Forest - Mean Squared Error (MSE): {mse_rf}')\n",
    "print(f'Random Forest - Root Mean Squared Error (RMSE): {rmse_rf}')\n",
    "print(f'Random Forest - R2 Score: {r2_rf}')\n",
    "print(f'Random Forest - Pearson Correlation Coefficient (r): {pearson_corr_rf}')\n",
    "print(f'Random Forest - Mean Absolute Error (MAE): {mae_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b691c0",
   "metadata": {},
   "source": [
    "    Mean Squared Error (MSE) and Root Mean Squared Error (RMSE): Look for models with lower MSE and RMSE values, as they indicate better precision in predictions. \n",
    "    R2 Score: A higher R2 Score indicates a better fit of the model to the data.\n",
    "\n",
    "    Pearson Correlation Coefficient (r): Look for models with a Pearson correlation coefficient closer to 1. A higher value indicates a better linear relationship between variables. \n",
    "\n",
    "    Mean Absolute Error (MAE): Look for models with a lower MAE, as it indicates a smaller absolute difference between predictions and actual observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359c8e2",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71fc4e",
   "metadata": {},
   "source": [
    "Cross-Validation Procedure:\n",
    "\n",
    "In k-fold cross-validation, the dataset is divided into k subsets (folds). The model is trained and evaluated k times, using a different fold for evaluation each time and the remaining folds for training. The performance metrics are then averaged across all folds to provide a more robust assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation for Random Forest (5-fold cross-validation)\n",
    "cv_scores_rf = cross_val_score(random_forest_model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_scores_rf = np.sqrt(-cv_scores_rf) # Convert the negative mean squared error to positive (sklearn returns neg_mean_squared_error)\n",
    "print(\"Random Forest - Cross-Validation RMSE Scores:\", cv_rmse_scores_rf)\n",
    "print(\"Mean CV RMSE Score for Random Forest:\", cv_rmse_scores_rf.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y_test, Y_pred_rf, alpha=0.4, label='Random Forest')\n",
    "plt.plot([0, 10], [0, 10], color='red', linestyle='--')  # Diagonal line for reference\n",
    "plt.title('Random Forest Regression') \n",
    "plt.xlabel('Experimental Toxicity', fontsize='large', fontweight='bold')\n",
    "plt.ylabel('Predicted Toxicity', fontsize='large', fontweight='bold')\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def performance_by_hyperparameter(n_estimators, random_state):\n",
    "    random_forest_model = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "    cv_scores_rf = cross_val_score(random_forest_model, X_train, Y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse_scores_rf = np.sqrt(-cv_scores_rf) # Convert the negative mean squared error to positive (sklearn returns neg_mean_squared_error)\n",
    "    return cv_rmse_scores_rf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dc6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_tuning = []\n",
    "for n_estimators in [20, 50, 100, 200, 500]:\n",
    "    for i in range(5):\n",
    "        rmse = performance_by_hyperparameter(n_estimators, i)\n",
    "        hyperparameter_tuning.append(dict(n_estimators=n_estimators, rmse=rmse))\n",
    "hyperparameter_tuning = pd.DataFrame.from_records(hyperparameter_tuning)\n",
    "hyperparameter_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82edb318",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(hyperparameter_tuning['n_estimators'], hyperparameter_tuning['rmse'])\n",
    "ax.set_xscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c2e6c",
   "metadata": {},
   "source": [
    "### Step 2: Using the Toxicity Model for Filtering Ligand-Based Virtual Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ca5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load your dataset\n",
    "Dataset = pd.read_csv('MoleculeDatabase_compounds_lipinski.csv')\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63731347",
   "metadata": {},
   "source": [
    "***Descriptor calculation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e036563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy only necessary columns\n",
    "columns  = ['chembl_id', 'smiles']\n",
    "Dataset2 = Dataset[columns].copy()\n",
    "Dataset2. head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd2da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maccs_fingerprints_list = []\n",
    "\n",
    "maccs_fingerprints_list = []\n",
    "\n",
    "# Step 3: Iterate through the SMILES column and calculate descriptors\n",
    "for k, row in Dataset2.iterrows():\n",
    "    mol = Chem.MolFromSmiles(row['smiles'])\n",
    "    \n",
    "        # Calculate MACCS fingerprints\n",
    "    maccs_fingerprints = AllChem.GetMACCSKeysFingerprint(mol)\n",
    "    maccs_fingerprints_list.append(\n",
    "        {\"chembl_id\": row['chembl_id'], \"fingerprints\": maccs_fingerprints, \"smiles\": row['smiles']} \n",
    "    )\n",
    "\n",
    "# Crear un DataFrame a partir de la lista de huellas peptídicas MACCS\n",
    "candidates = pd.DataFrame.from_records(maccs_fingerprints_list)\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf99f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(candidates['fingerprints'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates['Predicted_Severity'] = random_forest_model.predict(X)\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39179327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un histograma\n",
    "plt.hist(candidates['Predicted_Severity'], bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Agregar etiquetas y título\n",
    "plt.xlabel('Predicted Severity')\n",
    "plt.ylabel('Number of Compounds')\n",
    "plt.title('Distribution of Predicted Severity')\n",
    "\n",
    "# Mostrar el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe255be",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Repeat the exercise with a different model:\n",
    "\n",
    "- [Neural Networks](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor)\n",
    "- [Kernel Ridge Regression](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html#sklearn.kernel_ridge.KernelRidge)\n",
    "- [Nearest Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor)\n",
    "\n",
    "Send a figure with the final result (best prediction and hyperparameter validation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
